# auto-featurs

### Polars-native, schema-driven automatic feature generation

`auto-featurs` is a fast, composable, **Polars-native feature engineering library**.
It provides a declarative, type-safe way to generate large families of features (polynomial, arithmetic, comparison, lagged, aggregations, rolling windows, etc.) while retaining control over:

* **Schema** (column types, numeric/ordinal/nominal/datetime)
* **Feature layers** (build features on top of earlier generated ones)
* **Optimization** (skip redundant or symmetric features before they are generated)
* **Lazy execution** via Polars (`LazyFrame â†’ DataFrame`)

The main abstraction is the **Pipeline**, which is immutable and fully composable.

---

## âœ¨ Features

* ðŸš€ **Polars expressions**, not Python loops
* ðŸ§± **Layered feature engineering** (generate â†’ freeze â†’ generate next layer)
* ðŸ” **Redundancy-aware optimization** (e.g., avoid `A + B` and `B + A` duplicates)
* ðŸ”— **Schema-driven selection** (e.g., â€œall numeric columnsâ€)
* â± **Time-window & cumulative rolling aggregations**
* ðŸ§ª Fully immutable pipeline â€” no in-place mutation surprises

---

# Installation

```bash
pip install auto-featurs
```

---

# Quick Start

Below is a minimal but expressive example that highlights:

1. **Basic feature generation**
2. **Layering** â€” using derived features as inputs for subsequent layers
3. **Optimization** â€” reducing redundant feature creation

```python
import polars as pl
from auto_featurs.pipeline.pipeline import Pipeline
from auto_featurs.base.column_specification import ColumnSpecification, ColumnType
from auto_featurs.transformers.numeric_transformers import ArithmeticOperation
from auto_featurs.pipeline.optimizer import OptimizationLevel
```

---

# 1. Basic Example: Polynomial + Arithmetic

Consider a simple input frame:

```python
df = pl.LazyFrame({
    "x": [0, 1, 2, 3],
    "y": [10, 11, 12, 13],
})

schema = [
    ColumnSpecification.numeric("x"),
    ColumnSpecification.numeric("y"),
]
```

We build a pipeline:

```python
pipeline = (
    Pipeline(schema=schema)
    .with_polynomial(subset=ColumnType.NUMERIC, degrees=[2])
    .with_arithmetic(
        left_subset="x",
        right_subset="y",
        operations=[ArithmeticOperation.ADD, ArithmeticOperation.SUBTRACT],
    )
)
```

Collect the final output:

```python
result = pipeline.collect(df)
print(result)
```

**Output:**

```
shape: (4, 6)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ x   â”‚ y   â”‚ x_pow_2    â”‚ y_pow_2       â”‚ x_add_y â”‚ x_subtract_y â”‚
â”‚ --- â”‚ --- â”‚ ---         â”‚ ---            â”‚ ---      â”‚ ---             â”‚
â”‚ i64 â”‚ i64 â”‚ i64        â”‚ i64           â”‚ i64      â”‚ i64           â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0   â”‚ 10  â”‚ 0          â”‚ 100          â”‚ 10       â”‚ -10          â”‚
â”‚ 1   â”‚ 11  â”‚ 1          â”‚ 121          â”‚ 12       â”‚ -10          â”‚
â”‚ 2   â”‚ 12  â”‚ 4          â”‚ 144          â”‚ 14       â”‚ -10          â”‚
â”‚ 3   â”‚ 13  â”‚ 9          â”‚ 169          â”‚ 16       â”‚ -10          â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# 2. Layering: Building Features from Previous Layers

Layers let you â€œfreezeâ€ the current schema and then use the newly-generated columns as inputs to the next layer â€” enabling multi-stage feature generation.

```python
pipeline = Pipeline(schema=[ColumnSpecification.numeric("x")])

pipeline = pipeline.with_polynomial(subset=ColumnType.NUMERIC, degrees=[2])
pipeline = pipeline.with_new_layer()   # â† freeze layer 1 outputs

# Now â€œx_pow_2â€ is part of the schema, so it can be used as a numeric input
pipeline = pipeline.with_polynomial(subset=ColumnType.NUMERIC, degrees=[2])

df = pl.LazyFrame({"x": [0, 1, 2, 3]})
print(pipeline.collect(df))
```

**Output:**

```
shape: (4, 3)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ x   â”‚ x_pow_2    â”‚ x_pow_2_pow_2       â”‚
â”‚ i64 â”‚ i64        â”‚ i64                 â”‚
â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 0   â”‚ 0          â”‚ 0                   â”‚
â”‚ 1   â”‚ 1          â”‚ 1                   â”‚
â”‚ 2   â”‚ 4          â”‚ 16                  â”‚
â”‚ 3   â”‚ 9          â”‚ 81                  â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

This mirrors the test suite behavior but is cleaner and easier to follow.

---

# 3. Optimization: Avoiding Redundant Feature Generation

The pipeline uses an `Optimizer` to avoid predictable redundancies:

* **`SKIP_SELF`** removes operations like `x + x` or `x - x` when appropriate
* **`DEDUPLICATE_COMMUTATIVE`** removes symmetric pairs like `x + y` and `y + x`

Letâ€™s see a clear, visual comparison.

## Example Input

```python
df = pl.LazyFrame({
    "a": [0, 1, 2],
    "b": [10, 11, 12],
})
schema = [
    ColumnSpecification.numeric("a"),
    ColumnSpecification.numeric("b"),
]
```

## Pipeline (ADD + SUBTRACT)

```python
from auto_featurs.transformers.numeric_transformers import ArithmeticOperation

def build(optimization):
    return (
        Pipeline(schema=schema, optimization_level=optimization)
        .with_arithmetic(
            left_subset=ColumnType.NUMERIC,
            right_subset=ColumnType.NUMERIC,
            operations=[ArithmeticOperation.ADD, ArithmeticOperation.SUBTRACT],
        )
    )
```

---

## ðŸ”Ž OptimizationLevel.NONE (default)

```python
print(build(OptimizationLevel.NONE).collect(df))
```

**Generated columns:**

* a_add_a
* a_add_b
* b_add_a
* b_add_b
* a_subtract_a
* a_subtract_b
* b_subtract_a
* b_subtract_b

This is the â€œfull Cartesian explosion.â€

---

## ðŸ”Ž OptimizationLevel.SKIP_SELF

```python
print(build(OptimizationLevel.SKIP_SELF).collect(df))
```

Self-operations removed:

* a_add_a âŒ
* b_add_b âŒ
* a_subtract_a âŒ
* b_subtract_b âŒ

All cross-column combos remain.

---

## ðŸ”Ž OptimizationLevel.DEDUPLICATE_COMMUTATIVE

```python
print(build(OptimizationLevel.DEDUPLICATE_COMMUTATIVE).collect(df))
```

Removes everything from `SKIP_SELF` **plus** commutative duplicates:

* b_add_a âŒ because a_add_b already exists
* Subtraction stays distinct (non-commutative)

---

### Summary Table

| Optimization                | Self ops | (a,b) vs (b,a)              | Notes                                  |
| --------------------------- | -------- | --------------------------- | -------------------------------------- |
| **NONE**                    | kept     | kept                        | Full feature set                       |
| **SKIP_SELF**               | removed  | kept                        | Reduces noise; retains all cross terms |
| **DEDUPLICATE_COMMUTATIVE** | removed  | removed for commutative ops | Best for large numeric sets            |

This is exactly the behavior exercised in the test suite â€” now shown clearly in the README.

---

# API Overview

### Pipeline Construction

```python
Pipeline(
    schema: list[ColumnSpecification],
    transformers: Optional[list[list[Transformer]]] = None,
    optimization_level: OptimizationLevel = OptimizationLevel.NONE,
)
```

### Core Methods

| Method                                      | Description                                                |
| ------------------------------------------- | ---------------------------------------------------------- |
| `with_polynomial(subset, degrees)`          | x â†’ xÂ², xÂ³, â€¦                                              |
| `with_arithmetic(left, right, operations)`  | Add/Sub/Mul/Div combinations                               |
| `with_comparison(left, right, comparisons)` | x > y, x == y, â€¦                                           |
| `with_lagged(subset, lags, ...)`            | Lag features with optional groupings                       |
| `with_first_value(...)`                     | First value in group or time window                        |
| `with_arithmetic_aggregation(...)`          | Count/Sum/Mean/Std over groups or windows                  |
| `with_new_layer()`                          | Freeze current layer & use generated columns in next layer |
| `collect(lazyframe)`                        | Apply across all layers and return `pl.DataFrame`          |

All methods return **new pipelines** (pipelines are immutable).

---

# Roadmap

* ðŸ”œ Learned feature selection (correlation / mutual information / importance-based)
* ðŸ”œ Caching & materialization strategies
* ðŸ”œ Group-aware window expressions once supported by Polars' stable API
* ðŸ”œ Documentation site & examples gallery

---

# Contributing

PRs, issues, and discussions are welcome!
